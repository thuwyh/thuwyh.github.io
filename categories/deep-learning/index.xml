<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Deep Learning on 多头注意力</title>
    <link>https://www.yuanhao.site/categories/deep-learning/</link>
    <description>Recent content in Deep Learning on 多头注意力</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <lastBuildDate>Sun, 20 Jun 2021 10:25:03 +0000</lastBuildDate>
    <atom:link href="https://www.yuanhao.site/categories/deep-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Impvove Inference Efficiency with Batch Inference</title>
      <link>https://www.yuanhao.site/post/2021-06-20-inferlight/</link>
      <pubDate>Sun, 20 Jun 2021 10:25:03 +0000</pubDate>
      <guid>https://www.yuanhao.site/post/2021-06-20-inferlight/</guid>
      <description>As an algorithm engineer, it is inevitable that you will encounter the problem of bringing models online in your daily work. For some less demanding scenarios, you can handle this by utilizing a web framework: for each user request, call the model to infer and return the result. However, this straightforward implementation often fails to maximize the use of the GPU, and is slightly overwhelming for scenarios with high performance requirements.</description>
    </item>
    <item>
      <title>Tricks of Semantic Segmentation</title>
      <link>https://www.yuanhao.site/post/2021-05-30-segmentation-tricks/</link>
      <pubDate>Sun, 30 May 2021 10:25:03 +0000</pubDate>
      <guid>https://www.yuanhao.site/post/2021-05-30-segmentation-tricks/</guid>
      <description>{: .align-center style=&amp;ldquo;width:80%&amp;rdquo;} HuBMAP - Hacking the Kidney {: .align-caption style=&amp;ldquo;text-align:center;font-size:smaller&amp;rdquo;}
Last month, I spent some time doing the “HuBMAP - Hacking the Kidney” competition on Kaggle. The goal of this competition is the implementation of a successful and robust glomeruli FTU detector. It is a classical binary semantic segmentation problem. This is my second semantic segmentation competition, and our team ended up in 43rd place and won a silver medal.</description>
    </item>
    <item>
      <title>Training large model with your GPU</title>
      <link>https://www.yuanhao.site/post/2021-04-15-save-vram/</link>
      <pubDate>Thu, 15 Apr 2021 10:25:03 +0000</pubDate>
      <guid>https://www.yuanhao.site/post/2021-04-15-save-vram/</guid>
      <description>In the last post, I shared my story of the Kaggle Jigsaw Multilingual Toxic Comment Classification competition. At that time, I only had a 1080Ti with 11G VRAM, and this made it impossible for me to train the SOTA Roberta-XLM large model which requires larger VRAM than what I had. In this post, I want to share some tips about how to reduce the VRAM usage so that you can train larger deep neural networks with your GPU.</description>
    </item>
  </channel>
</rss>
