<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>十分钟读懂beam search-1 | 多头注意力</title>
<meta name="keywords" content="NLP, 文本生成, beam search">
<meta name="description" content="最近研究了一下用基于BERT的encoder-decoder结构做文本生成任务，碰巧管老师昨天的文章也介绍了以生成任务见长的GPT模型，于是决定用两篇文章大家介绍一下在文本生成任务中常用的解码策略Beam Search（集束搜索）。
解码及贪心搜索 生成式任务相比普通的分类、tagging等NLP任务会复杂不少。在生成的时候，模型的输出是一个时间步一个时间步依次获得的，而且前面时间步的结果还会影响后面时间步的结果。也就是说，每一个时间步，模型给出的都是基于历史生成结果的条件概率。为了生成完整的句子，需要一个称为解码的额外动作来融合模型多个时间步的输出，而且使得最终得到的序列的每一步条件概率连乘起来最大。
在文本生成任务中，每一个时间步可能的输出种类称为字典大小(vocabulary size，我们用$v$表示)，进行T步随机的生成可能获得的结果总共有$v^T$种。拿中文文本生成来说，$v$的值大约是5000-6000，即常用汉字的个数。在如此大的基数下，遍历整个生成空间是不现实的。
最容易想到的策略是贪心搜索，即每一个时间步都取出一个条件概率最大的输出，再将从开始到当前步的结果作为输入去获得下一个时间步的输出，直到模型给出生成结束的标志。例如下图，每一个时间步都取出了条件概率最大一个结果，生成了序列[A,B,C]。
很明显，这样做将原来指数级别的求解空间直接压缩到了与长度线性相关的大小。由于丢弃了绝大多数的可能解，这种关注当下的策略无法保证最终得到的序列概率是最优的。
Beam Search 而beam search是对贪心策略一个改进。思路也很简单，就是稍微放宽一些考察的范围。在每一个时间步，不再只保留当前分数最高的1个输出，而是保留num_beams个。当num_beams=1时集束搜索就退化成了贪心搜索。
下图是一个实际的例子，每个时间步有ABCDE共5种可能的输出，即$v=5$，图中的num_beams=2，也就是说每个时间步都会保留到当前步为止条件概率最优的2个序列。
在第一个时间步，A和C是最优的两个，因此得到了两个结果[A],[C]，其他三个就被抛弃了； 第二步会基于这两个结果继续进行生成，在A这个分支可以得到5个候选人，[AA],[AB],[AC],[AD],[AE]，C也同理得到5个，此时会对这10个进行统一排名，再保留最优的两个，即图中的[AB]和[CE]； 第三步同理，也会从新的10个候选人里再保留最好的两个，最后得到了[ABD],[CED]两个结果。 可以发现，beam search在每一步需要考察的候选人数量是贪心搜索的num_beams倍，因此是一种牺牲时间换性能的方法。
以上就是Beam Search的基本概念，下面我们解析一种高效率实现方式。
Beam Search代码解析 Beam Search的原理虽然简单，但实际实现的时候却有很多细节要考虑。下面要解析这个实现出自于NLP界著名Python包Transformers，我为了说明方便做了一些改动。
一个正确且高效的算法需要处理的问题大概有两个：
充分利用硬件，可以处理批量数据，且尽量使用并行计算少用循环 处理好长短不同的生成结果 下面是基础版的beam search函数定义。其中context是编码器编码获得的向量，batch_size是每批数据中包含的样本量，bos_token_id是句子开头标志的token id，pad_token_id是用于填充的token id，eos_token_id是句子结束标志的token id。这里给参数填上的默认值和我们后面讲解时使用的例子是一致的。
def beam_search_generate(context, batch_size=3, max_length=20, min_length=2, num_beams=2, bos_token_id=101, pad_token_id=0, eos_token_id=102, ): pass 在函数中主要执行以下三个步骤：
准备初始输入 在当前生成的序列长度未达到max_length时扩展生成序列 准备最终输出的序列 下面我们分别解析。
准备初始输入 # 建立beam容器，每个样本一个 generated_hyps = [ BeamHypotheses(num_beams, max_length, length_penalty, early_stopping=early_stopping) for _ in range(batch_size) ] # 每个beam容器的得分，共batch_size*num_beams个 beam_scores = torch.zeros((batch_size, num_beams), dtype=torch.float, device=encoder_input_ids.">
<meta name="author" content="">
<link rel="canonical" href="https://www.yuanhao.site/post/2020-03-20-beamsearch1/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.b609c58d5c11bb90b1a54e04005d74ad1ddf22165eb79f5533967e57df9c3b50.css" integrity="sha256-tgnFjVwRu5CxpU4EAF10rR3fIhZet59VM5Z&#43;V9&#43;cO1A=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://www.yuanhao.site/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://www.yuanhao.site/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://www.yuanhao.site/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://www.yuanhao.site/apple-touch-icon.png">
<link rel="mask-icon" href="https://www.yuanhao.site/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="十分钟读懂beam search-1" />
<meta property="og:description" content="最近研究了一下用基于BERT的encoder-decoder结构做文本生成任务，碰巧管老师昨天的文章也介绍了以生成任务见长的GPT模型，于是决定用两篇文章大家介绍一下在文本生成任务中常用的解码策略Beam Search（集束搜索）。
解码及贪心搜索 生成式任务相比普通的分类、tagging等NLP任务会复杂不少。在生成的时候，模型的输出是一个时间步一个时间步依次获得的，而且前面时间步的结果还会影响后面时间步的结果。也就是说，每一个时间步，模型给出的都是基于历史生成结果的条件概率。为了生成完整的句子，需要一个称为解码的额外动作来融合模型多个时间步的输出，而且使得最终得到的序列的每一步条件概率连乘起来最大。
在文本生成任务中，每一个时间步可能的输出种类称为字典大小(vocabulary size，我们用$v$表示)，进行T步随机的生成可能获得的结果总共有$v^T$种。拿中文文本生成来说，$v$的值大约是5000-6000，即常用汉字的个数。在如此大的基数下，遍历整个生成空间是不现实的。
最容易想到的策略是贪心搜索，即每一个时间步都取出一个条件概率最大的输出，再将从开始到当前步的结果作为输入去获得下一个时间步的输出，直到模型给出生成结束的标志。例如下图，每一个时间步都取出了条件概率最大一个结果，生成了序列[A,B,C]。
很明显，这样做将原来指数级别的求解空间直接压缩到了与长度线性相关的大小。由于丢弃了绝大多数的可能解，这种关注当下的策略无法保证最终得到的序列概率是最优的。
Beam Search 而beam search是对贪心策略一个改进。思路也很简单，就是稍微放宽一些考察的范围。在每一个时间步，不再只保留当前分数最高的1个输出，而是保留num_beams个。当num_beams=1时集束搜索就退化成了贪心搜索。
下图是一个实际的例子，每个时间步有ABCDE共5种可能的输出，即$v=5$，图中的num_beams=2，也就是说每个时间步都会保留到当前步为止条件概率最优的2个序列。
在第一个时间步，A和C是最优的两个，因此得到了两个结果[A],[C]，其他三个就被抛弃了； 第二步会基于这两个结果继续进行生成，在A这个分支可以得到5个候选人，[AA],[AB],[AC],[AD],[AE]，C也同理得到5个，此时会对这10个进行统一排名，再保留最优的两个，即图中的[AB]和[CE]； 第三步同理，也会从新的10个候选人里再保留最好的两个，最后得到了[ABD],[CED]两个结果。 可以发现，beam search在每一步需要考察的候选人数量是贪心搜索的num_beams倍，因此是一种牺牲时间换性能的方法。
以上就是Beam Search的基本概念，下面我们解析一种高效率实现方式。
Beam Search代码解析 Beam Search的原理虽然简单，但实际实现的时候却有很多细节要考虑。下面要解析这个实现出自于NLP界著名Python包Transformers，我为了说明方便做了一些改动。
一个正确且高效的算法需要处理的问题大概有两个：
充分利用硬件，可以处理批量数据，且尽量使用并行计算少用循环 处理好长短不同的生成结果 下面是基础版的beam search函数定义。其中context是编码器编码获得的向量，batch_size是每批数据中包含的样本量，bos_token_id是句子开头标志的token id，pad_token_id是用于填充的token id，eos_token_id是句子结束标志的token id。这里给参数填上的默认值和我们后面讲解时使用的例子是一致的。
def beam_search_generate(context, batch_size=3, max_length=20, min_length=2, num_beams=2, bos_token_id=101, pad_token_id=0, eos_token_id=102, ): pass 在函数中主要执行以下三个步骤：
准备初始输入 在当前生成的序列长度未达到max_length时扩展生成序列 准备最终输出的序列 下面我们分别解析。
准备初始输入 # 建立beam容器，每个样本一个 generated_hyps = [ BeamHypotheses(num_beams, max_length, length_penalty, early_stopping=early_stopping) for _ in range(batch_size) ] # 每个beam容器的得分，共batch_size*num_beams个 beam_scores = torch.zeros((batch_size, num_beams), dtype=torch.float, device=encoder_input_ids." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://www.yuanhao.site/post/2020-03-20-beamsearch1/" /><meta property="article:section" content="post" />
<meta property="article:published_time" content="2020-03-20T00:00:00+00:00" />
<meta property="article:modified_time" content="2020-03-20T00:00:00+00:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="十分钟读懂beam search-1"/>
<meta name="twitter:description" content="最近研究了一下用基于BERT的encoder-decoder结构做文本生成任务，碰巧管老师昨天的文章也介绍了以生成任务见长的GPT模型，于是决定用两篇文章大家介绍一下在文本生成任务中常用的解码策略Beam Search（集束搜索）。
解码及贪心搜索 生成式任务相比普通的分类、tagging等NLP任务会复杂不少。在生成的时候，模型的输出是一个时间步一个时间步依次获得的，而且前面时间步的结果还会影响后面时间步的结果。也就是说，每一个时间步，模型给出的都是基于历史生成结果的条件概率。为了生成完整的句子，需要一个称为解码的额外动作来融合模型多个时间步的输出，而且使得最终得到的序列的每一步条件概率连乘起来最大。
在文本生成任务中，每一个时间步可能的输出种类称为字典大小(vocabulary size，我们用$v$表示)，进行T步随机的生成可能获得的结果总共有$v^T$种。拿中文文本生成来说，$v$的值大约是5000-6000，即常用汉字的个数。在如此大的基数下，遍历整个生成空间是不现实的。
最容易想到的策略是贪心搜索，即每一个时间步都取出一个条件概率最大的输出，再将从开始到当前步的结果作为输入去获得下一个时间步的输出，直到模型给出生成结束的标志。例如下图，每一个时间步都取出了条件概率最大一个结果，生成了序列[A,B,C]。
很明显，这样做将原来指数级别的求解空间直接压缩到了与长度线性相关的大小。由于丢弃了绝大多数的可能解，这种关注当下的策略无法保证最终得到的序列概率是最优的。
Beam Search 而beam search是对贪心策略一个改进。思路也很简单，就是稍微放宽一些考察的范围。在每一个时间步，不再只保留当前分数最高的1个输出，而是保留num_beams个。当num_beams=1时集束搜索就退化成了贪心搜索。
下图是一个实际的例子，每个时间步有ABCDE共5种可能的输出，即$v=5$，图中的num_beams=2，也就是说每个时间步都会保留到当前步为止条件概率最优的2个序列。
在第一个时间步，A和C是最优的两个，因此得到了两个结果[A],[C]，其他三个就被抛弃了； 第二步会基于这两个结果继续进行生成，在A这个分支可以得到5个候选人，[AA],[AB],[AC],[AD],[AE]，C也同理得到5个，此时会对这10个进行统一排名，再保留最优的两个，即图中的[AB]和[CE]； 第三步同理，也会从新的10个候选人里再保留最好的两个，最后得到了[ABD],[CED]两个结果。 可以发现，beam search在每一步需要考察的候选人数量是贪心搜索的num_beams倍，因此是一种牺牲时间换性能的方法。
以上就是Beam Search的基本概念，下面我们解析一种高效率实现方式。
Beam Search代码解析 Beam Search的原理虽然简单，但实际实现的时候却有很多细节要考虑。下面要解析这个实现出自于NLP界著名Python包Transformers，我为了说明方便做了一些改动。
一个正确且高效的算法需要处理的问题大概有两个：
充分利用硬件，可以处理批量数据，且尽量使用并行计算少用循环 处理好长短不同的生成结果 下面是基础版的beam search函数定义。其中context是编码器编码获得的向量，batch_size是每批数据中包含的样本量，bos_token_id是句子开头标志的token id，pad_token_id是用于填充的token id，eos_token_id是句子结束标志的token id。这里给参数填上的默认值和我们后面讲解时使用的例子是一致的。
def beam_search_generate(context, batch_size=3, max_length=20, min_length=2, num_beams=2, bos_token_id=101, pad_token_id=0, eos_token_id=102, ): pass 在函数中主要执行以下三个步骤：
准备初始输入 在当前生成的序列长度未达到max_length时扩展生成序列 准备最终输出的序列 下面我们分别解析。
准备初始输入 # 建立beam容器，每个样本一个 generated_hyps = [ BeamHypotheses(num_beams, max_length, length_penalty, early_stopping=early_stopping) for _ in range(batch_size) ] # 每个beam容器的得分，共batch_size*num_beams个 beam_scores = torch.zeros((batch_size, num_beams), dtype=torch.float, device=encoder_input_ids."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Posts",
      "item": "https://www.yuanhao.site/post/"
    }, 
    {
      "@type": "ListItem",
      "position":  3 ,
      "name": "十分钟读懂beam search-1",
      "item": "https://www.yuanhao.site/post/2020-03-20-beamsearch1/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "十分钟读懂beam search-1",
  "name": "十分钟读懂beam search-1",
  "description": "最近研究了一下用基于BERT的encoder-decoder结构做文本生成任务，碰巧管老师昨天的文章也介绍了以生成任务见长的GPT模型，于是决定用两篇文章大家介绍一下在文本生成任务中常用的解码策略Beam Search（集束搜索）。\n解码及贪心搜索 生成式任务相比普通的分类、tagging等NLP任务会复杂不少。在生成的时候，模型的输出是一个时间步一个时间步依次获得的，而且前面时间步的结果还会影响后面时间步的结果。也就是说，每一个时间步，模型给出的都是基于历史生成结果的条件概率。为了生成完整的句子，需要一个称为解码的额外动作来融合模型多个时间步的输出，而且使得最终得到的序列的每一步条件概率连乘起来最大。\n在文本生成任务中，每一个时间步可能的输出种类称为字典大小(vocabulary size，我们用$v$表示)，进行T步随机的生成可能获得的结果总共有$v^T$种。拿中文文本生成来说，$v$的值大约是5000-6000，即常用汉字的个数。在如此大的基数下，遍历整个生成空间是不现实的。\n最容易想到的策略是贪心搜索，即每一个时间步都取出一个条件概率最大的输出，再将从开始到当前步的结果作为输入去获得下一个时间步的输出，直到模型给出生成结束的标志。例如下图，每一个时间步都取出了条件概率最大一个结果，生成了序列[A,B,C]。\n很明显，这样做将原来指数级别的求解空间直接压缩到了与长度线性相关的大小。由于丢弃了绝大多数的可能解，这种关注当下的策略无法保证最终得到的序列概率是最优的。\nBeam Search 而beam search是对贪心策略一个改进。思路也很简单，就是稍微放宽一些考察的范围。在每一个时间步，不再只保留当前分数最高的1个输出，而是保留num_beams个。当num_beams=1时集束搜索就退化成了贪心搜索。\n下图是一个实际的例子，每个时间步有ABCDE共5种可能的输出，即$v=5$，图中的num_beams=2，也就是说每个时间步都会保留到当前步为止条件概率最优的2个序列。\n在第一个时间步，A和C是最优的两个，因此得到了两个结果[A],[C]，其他三个就被抛弃了； 第二步会基于这两个结果继续进行生成，在A这个分支可以得到5个候选人，[AA],[AB],[AC],[AD],[AE]，C也同理得到5个，此时会对这10个进行统一排名，再保留最优的两个，即图中的[AB]和[CE]； 第三步同理，也会从新的10个候选人里再保留最好的两个，最后得到了[ABD],[CED]两个结果。 可以发现，beam search在每一步需要考察的候选人数量是贪心搜索的num_beams倍，因此是一种牺牲时间换性能的方法。\n以上就是Beam Search的基本概念，下面我们解析一种高效率实现方式。\nBeam Search代码解析 Beam Search的原理虽然简单，但实际实现的时候却有很多细节要考虑。下面要解析这个实现出自于NLP界著名Python包Transformers，我为了说明方便做了一些改动。\n一个正确且高效的算法需要处理的问题大概有两个：\n充分利用硬件，可以处理批量数据，且尽量使用并行计算少用循环 处理好长短不同的生成结果 下面是基础版的beam search函数定义。其中context是编码器编码获得的向量，batch_size是每批数据中包含的样本量，bos_token_id是句子开头标志的token id，pad_token_id是用于填充的token id，eos_token_id是句子结束标志的token id。这里给参数填上的默认值和我们后面讲解时使用的例子是一致的。\ndef beam_search_generate(context, batch_size=3, max_length=20, min_length=2, num_beams=2, bos_token_id=101, pad_token_id=0, eos_token_id=102, ): pass 在函数中主要执行以下三个步骤：\n准备初始输入 在当前生成的序列长度未达到max_length时扩展生成序列 准备最终输出的序列 下面我们分别解析。\n准备初始输入 # 建立beam容器，每个样本一个 generated_hyps = [ BeamHypotheses(num_beams, max_length, length_penalty, early_stopping=early_stopping) for _ in range(batch_size) ] # 每个beam容器的得分，共batch_size*num_beams个 beam_scores = torch.zeros((batch_size, num_beams), dtype=torch.float, device=encoder_input_ids.",
  "keywords": [
    "NLP", "文本生成", "beam search"
  ],
  "articleBody": "最近研究了一下用基于BERT的encoder-decoder结构做文本生成任务，碰巧管老师昨天的文章也介绍了以生成任务见长的GPT模型，于是决定用两篇文章大家介绍一下在文本生成任务中常用的解码策略Beam Search（集束搜索）。\n解码及贪心搜索 生成式任务相比普通的分类、tagging等NLP任务会复杂不少。在生成的时候，模型的输出是一个时间步一个时间步依次获得的，而且前面时间步的结果还会影响后面时间步的结果。也就是说，每一个时间步，模型给出的都是基于历史生成结果的条件概率。为了生成完整的句子，需要一个称为解码的额外动作来融合模型多个时间步的输出，而且使得最终得到的序列的每一步条件概率连乘起来最大。\n在文本生成任务中，每一个时间步可能的输出种类称为字典大小(vocabulary size，我们用$v$表示)，进行T步随机的生成可能获得的结果总共有$v^T$种。拿中文文本生成来说，$v$的值大约是5000-6000，即常用汉字的个数。在如此大的基数下，遍历整个生成空间是不现实的。\n最容易想到的策略是贪心搜索，即每一个时间步都取出一个条件概率最大的输出，再将从开始到当前步的结果作为输入去获得下一个时间步的输出，直到模型给出生成结束的标志。例如下图，每一个时间步都取出了条件概率最大一个结果，生成了序列[A,B,C]。\n很明显，这样做将原来指数级别的求解空间直接压缩到了与长度线性相关的大小。由于丢弃了绝大多数的可能解，这种关注当下的策略无法保证最终得到的序列概率是最优的。\nBeam Search 而beam search是对贪心策略一个改进。思路也很简单，就是稍微放宽一些考察的范围。在每一个时间步，不再只保留当前分数最高的1个输出，而是保留num_beams个。当num_beams=1时集束搜索就退化成了贪心搜索。\n下图是一个实际的例子，每个时间步有ABCDE共5种可能的输出，即$v=5$，图中的num_beams=2，也就是说每个时间步都会保留到当前步为止条件概率最优的2个序列。\n在第一个时间步，A和C是最优的两个，因此得到了两个结果[A],[C]，其他三个就被抛弃了； 第二步会基于这两个结果继续进行生成，在A这个分支可以得到5个候选人，[AA],[AB],[AC],[AD],[AE]，C也同理得到5个，此时会对这10个进行统一排名，再保留最优的两个，即图中的[AB]和[CE]； 第三步同理，也会从新的10个候选人里再保留最好的两个，最后得到了[ABD],[CED]两个结果。 可以发现，beam search在每一步需要考察的候选人数量是贪心搜索的num_beams倍，因此是一种牺牲时间换性能的方法。\n以上就是Beam Search的基本概念，下面我们解析一种高效率实现方式。\nBeam Search代码解析 Beam Search的原理虽然简单，但实际实现的时候却有很多细节要考虑。下面要解析这个实现出自于NLP界著名Python包Transformers，我为了说明方便做了一些改动。\n一个正确且高效的算法需要处理的问题大概有两个：\n充分利用硬件，可以处理批量数据，且尽量使用并行计算少用循环 处理好长短不同的生成结果 下面是基础版的beam search函数定义。其中context是编码器编码获得的向量，batch_size是每批数据中包含的样本量，bos_token_id是句子开头标志的token id，pad_token_id是用于填充的token id，eos_token_id是句子结束标志的token id。这里给参数填上的默认值和我们后面讲解时使用的例子是一致的。\ndef beam_search_generate(context, batch_size=3, max_length=20, min_length=2, num_beams=2, bos_token_id=101, pad_token_id=0, eos_token_id=102, ): pass 在函数中主要执行以下三个步骤：\n准备初始输入 在当前生成的序列长度未达到max_length时扩展生成序列 准备最终输出的序列 下面我们分别解析。\n准备初始输入 # 建立beam容器，每个样本一个 generated_hyps = [ BeamHypotheses(num_beams, max_length, length_penalty, early_stopping=early_stopping) for _ in range(batch_size) ] # 每个beam容器的得分，共batch_size*num_beams个 beam_scores = torch.zeros((batch_size, num_beams), dtype=torch.float, device=encoder_input_ids.device) beam_scores = beam_scores.view(-1) # 每个样本是否完成生成，共batch_size个 done = [False for _ in range(batch_size)] # 为了并行计算，一次生成batch_size*num_beams个序列 # 第一步自动填入bos_token input_ids = torch.full( (batch_size*num_beams, 1), bos_token_id, dtype=torch.long, device=next(self.parameters()).device, ) # 当前长度设为1 cur_len = 1 其中BeamHypotheses是一个容器类，每个样本绑定一个。每个容器中会维护num_beams个当前最优的序列。当往容器中添加一个序列而导致序列数大于num_beams的时候，它会自动踢掉分数最低的那个序列。类代码如下。\nclass BeamHypotheses(object): def __init__(self, num_beams, max_length, length_penalty): \"\"\" Initialize n-best list of hypotheses. \"\"\" self.max_length = max_length - 1 # ignoring bos_token self.num_beams = num_beams self.beams = [] self.worst_score = 1e9 def __len__(self): \"\"\" Number of hypotheses in the list. \"\"\" return len(self.beams) def add(self, hyp, sum_logprobs): \"\"\" Add a new hypothesis to the list. \"\"\" score = sum_logprobs / len(hyp) ** self.length_penalty if len(self) \u003c self.num_beams or score \u003e self.worst_score: # 可更新的情况：数量未饱和或超过最差得分 self.beams.append((score, hyp)) if len(self) \u003e self.num_beams: # 数量饱和需要删掉一个最差的 sorted_scores = sorted([(s, idx) for idx, (s, _) in enumerate(self.beams)]) del self.beams[sorted_scores[0][1]] self.worst_score = sorted_scores[1][0] else: self.worst_score = min(score, self.worst_score) def is_done(self, best_sum_logprobs, cur_len=None): \"\"\" 相关样本是否已经完成生成。 best_sum_logprobs是新的候选序列中的最高得分。 \"\"\" if len(self) \u003c self.num_beams: return False else: if cur_len is None: cur_len = self.max_length cur_score = best_sum_logprobs / cur_len ** self.length_penalty # 是否最高分比当前保存的最低分还差 ret = self.worst_score \u003e= cur_score return ret 序列扩展 序列扩展是beam search的核心过程，我们特地画了一张图来解释这个版本的实现策略。\n下面对照这个图来讲解代码。\nwhile cur_len \u003c max_length: # 将编码器得到的上下文向量和当前结果输入解码器，即图中1 output = decoder.decode_next_step(context, input_ids) # 输出矩阵维度为：(batch*num_beams)*cur_len*vocab_size # 取出最后一个时间步的各token概率，即当前条件概率 # (batch*num_beams)*vocab_size scores = next_token_logits = output[:, -1, :] ########################### # 这里可以做一大堆操作减少重复 # ########################### # 计算序列条件概率的，因为取了log，所以直接相加即可。得到图中2矩阵 # (batch_size * num_beams, vocab_size) next_scores = scores + beam_scores[:, None].expand_as(scores) # 为了提速，将结果重排成图中3的形状 next_scores = next_scores.view( batch_size, num_beams * vocab_size ) # (batch_size, num_beams * vocab_size) # 取出分数最高的token（图中黑点）和其对应得分 # sorted=True，保证返回序列是有序的 next_scores, next_tokens = torch.topk(next_scores, 2 * num_beams, dim=1, largest=True, sorted=True) # 下一个时间步整个batch的beam列表 # 列表中的每一个元素都是三元组 # (分数, token_id, beam_id) next_batch_beam = [] # 对每一个样本进行扩展 for batch_idx in range(batch_size): # 检查样本是否已经生成结束 if done[batch_idx]: # 对于已经结束的句子，待添加的是pad token next_batch_beam.extend([(0, pad_token_id, 0)] * num_beams) # pad the batch continue # 当前样本下一个时间步的beam列表 next_sent_beam = [] # 对于还未结束的样本需要找到分数最高的num_beams个扩展 # 注意，next_scores和next_tokens是对应的 # 而且已经按照next_scores排好顺序 for beam_token_rank, (beam_token_id, beam_token_score) in enumerate( zip(next_tokens[batch_idx], next_scores[batch_idx]) ): # get beam and word IDs # 这两行可参考图中3进行理解 beam_id = beam_token_id // vocab_size token_id = beam_token_id % vocab_size effective_beam_id = batch_idx * num_beams + beam_id # 如果出现了EOS token说明已经生成了完整句子 if (eos_token_id is not None) and (token_id.item() == eos_token_id): # if beam_token does not belong to top num_beams tokens, it should not be added is_beam_token_worse_than_top_num_beams = beam_token_rank \u003e= num_beams if is_beam_token_worse_than_top_num_beams: continue # 往容器中添加这个序列 generated_hyps[batch_idx].add( input_ids[effective_beam_id].clone(), beam_token_score.item(), ) else: # add next predicted word if it is not eos_token next_sent_beam.append((beam_token_score, token_id, effective_beam_id)) # 扩展num_beams个就够了 if len(next_sent_beam) == num_beams: break # 检查这个样本是否已经生成完了，有两种情况 # 1. 已经记录过该样本结束 # 2. 新的结果没有使结果改善 done[batch_idx] = done[batch_idx] or generated_hyps[batch_idx].is_done( next_scores[batch_idx].max().item(), cur_len=cur_len ) # 把当前样本的结果添加到batch结果的后面 next_batch_beam.extend(next_sent_beam) # 如果全部样本都已经生成结束便可以直接退出了 if all(done): break # 把三元组列表再还原成三个独立列表 beam_scores = beam_scores.new([x[0] for x in next_batch_beam]) beam_tokens = input_ids.new([x[1] for x in next_batch_beam]) beam_idx = input_ids.new([x[2] for x in next_batch_beam]) # 准备下一时刻的解码器输入 # 取出实际被扩展的beam input_ids = input_ids[beam_idx, :] # 在这些beam后面接上新生成的token input_ids = torch.cat([input_ids, beam_tokens.unsqueeze(1)], dim=-1) # 更新当前长度 cur_len = cur_len + 1 # end of length while 乍一看是不是有些复杂，我感觉关键的有以下几点：\n只有出现了EOS token才会将生成的序列装进该样本对应的容器中 当前input_ids保存着当前得分最高的num_beams个序列 准备输出 上面那个while循环跳出意味着已经生成了长度为max_length的文本，比较理想的情况是所有的句子都已经生成出了eos_token_id，即句子生成结束了。但并不是所有情况都这样，对于那些”意犹未尽“的样本，我们需要先手动结束。\n# 将未结束的生成结果结束，并置入容器中 for batch_idx in range(batch_size): # 已经结束的样本不需处理 if done[batch_idx]: continue # 把结果加入到generated_hyps容器 for beam_id in range(num_beams): effective_beam_id = batch_idx * num_beams + beam_id final_score = beam_scores[effective_beam_id].item() final_tokens = input_ids[effective_beam_id] generated_hyps[batch_idx].add(final_tokens, final_score) 经过上面的处理，所有生成好的句子都已经保存在generated_hyps容器中，每个容器内保存着num_beams个序列，最后就是输出期望个数的句子。\n# select the best hypotheses，最终输出 # 每个样本返回几个句子 output_num_return_sequences_per_batch = 1 # 记录每个返回句子的长度，用于后面pad sent_lengths = input_ids.new(output_batch_size) best = [] # 对每个样本取出最好的output_num_return_sequences_per_batch个句子 for i, hypotheses in enumerate(generated_hyps): sorted_hyps = sorted(hypotheses.beams, key=lambda x: x[0]) for j in range(output_num_return_sequences_per_batch): effective_batch_idx = output_num_return_sequences_per_batch * i + j best_hyp = sorted_hyps.pop()[1] sent_lengths[effective_batch_idx] = len(best_hyp) best.append(best_hyp) # 如果长短不一则pad句子，使得最后返回结果的长度一样 if sent_lengths.min().item() != sent_lengths.max().item(): sent_max_len = min(sent_lengths.max().item() + 1, max_length) # 先把输出矩阵填满PAD token decoded = input_ids.new(output_batch_size, sent_max_len).fill_(pad_token_id) # 填入真正的内容 for i, hypo in enumerate(best): decoded[i, : sent_lengths[i]] = hypo # 填上eos token if sent_lengths[i] \u003c max_length: decoded[i, sent_lengths[i]] = eos_token_id else: # 所有生成序列都还没结束，直接堆叠即可 decoded = torch.stack(best).type(torch.long).to(next(self.parameters()).device) # 返回的结果包含BOS token return decoded 总结 好了，上面就是最基础的beam search算法。这样生成出来的结果已经会比贪心搜索好一些，但还是会遇到诸如词语重复这样的问题。其实已经有很多针对重复问题的研究，我们在代码中也已经留出了位置，下期再说咯。\n",
  "wordCount" : "674",
  "inLanguage": "en",
  "datePublished": "2020-03-20T00:00:00Z",
  "dateModified": "2020-03-20T00:00:00Z",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://www.yuanhao.site/post/2020-03-20-beamsearch1/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "多头注意力",
    "logo": {
      "@type": "ImageObject",
      "url": "https://www.yuanhao.site/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://www.yuanhao.site" accesskey="h" title="多头注意力 (Alt + H)">多头注意力</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://www.yuanhao.site/archive" title="Archive">
                    <span>Archive</span>
                </a>
            </li>
            <li>
                <a href="https://www.yuanhao.site/categories/" title="Categories">
                    <span>Categories</span>
                </a>
            </li>
            <li>
                <a href="https://www.yuanhao.site/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://www.yuanhao.site">Home</a>&nbsp;»&nbsp;<a href="https://www.yuanhao.site/post/">Posts</a></div>
    <h1 class="post-title entry-hint-parent">
      十分钟读懂beam search-1
    </h1>
    <div class="post-meta"><span title='2020-03-20 00:00:00 +0000 UTC'>March 20, 2020</span>&nbsp;·&nbsp;4 min

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#%e8%a7%a3%e7%a0%81%e5%8f%8a%e8%b4%aa%e5%bf%83%e6%90%9c%e7%b4%a2" aria-label="解码及贪心搜索">解码及贪心搜索</a></li>
                <li>
                    <a href="#beam-search" aria-label="Beam Search">Beam Search</a></li>
                <li>
                    <a href="#beam-search%e4%bb%a3%e7%a0%81%e8%a7%a3%e6%9e%90" aria-label="Beam Search代码解析">Beam Search代码解析</a><ul>
                        
                <li>
                    <a href="#%e5%87%86%e5%a4%87%e5%88%9d%e5%a7%8b%e8%be%93%e5%85%a5" aria-label="准备初始输入">准备初始输入</a></li>
                <li>
                    <a href="#%e5%ba%8f%e5%88%97%e6%89%a9%e5%b1%95" aria-label="序列扩展">序列扩展</a></li>
                <li>
                    <a href="#%e5%87%86%e5%a4%87%e8%be%93%e5%87%ba" aria-label="准备输出">准备输出</a></li></ul>
                </li>
                <li>
                    <a href="#%e6%80%bb%e7%bb%93" aria-label="总结">总结</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><p>最近研究了一下用基于BERT的encoder-decoder结构做文本生成任务，碰巧管老师昨天的文章也介绍了以生成任务见长的GPT模型，于是决定用两篇文章大家介绍一下在文本生成任务中常用的解码策略Beam Search（集束搜索）。</p>
<h2 id="解码及贪心搜索">解码及贪心搜索<a hidden class="anchor" aria-hidden="true" href="#解码及贪心搜索">#</a></h2>
<p>生成式任务相比普通的分类、tagging等NLP任务会复杂不少。在生成的时候，模型的输出是一个时间步一个时间步依次获得的，而且前面时间步的结果还会影响后面时间步的结果。也就是说，每一个时间步，模型给出的都是基于历史生成结果的条件概率。为了生成完整的句子，需要一个称为解码的额外动作来融合模型多个时间步的输出，而且使得最终得到的序列的每一步条件概率连乘起来最大。</p>
<p>在文本生成任务中，每一个时间步可能的输出种类称为字典大小(vocabulary size，我们用$v$表示)，进行T步随机的生成可能获得的结果总共有$v^T$种。拿中文文本生成来说，$v$的值大约是5000-6000，即常用汉字的个数。在如此大的基数下，遍历整个生成空间是不现实的。</p>
<p>最容易想到的策略是贪心搜索，即每一个时间步都取出一个条件概率最大的输出，再将从开始到当前步的结果作为输入去获得下一个时间步的输出，直到模型给出生成结束的标志。例如下图，每一个时间步都取出了条件概率最大一个结果，生成了序列<code>[A,B,C]</code>。</p>
<p><img loading="lazy" src="/assets/beamsearch/greedy.svg" alt="贪心搜索示意图"  />
</p>
<p>很明显，这样做将原来指数级别的求解空间直接压缩到了与长度线性相关的大小。由于丢弃了绝大多数的可能解，这种<strong>关注当下</strong>的策略无法保证最终得到的序列概率是最优的。</p>
<h2 id="beam-search">Beam Search<a hidden class="anchor" aria-hidden="true" href="#beam-search">#</a></h2>
<p>而beam search是对贪心策略一个改进。思路也很简单，就是稍微放宽一些考察的范围。在每一个时间步，不再只保留当前分数最高的<strong>1</strong>个输出，而是保留<strong>num_beams</strong>个。当num_beams=1时集束搜索就退化成了贪心搜索。</p>
<p>下图是一个实际的例子，每个时间步有ABCDE共5种可能的输出，即$v=5$，图中的num_beams=2，也就是说每个时间步都会保留到当前步为止条件概率最优的2个序列。</p>
<p><img loading="lazy" src="/assets/beamsearch/beam_search.png" alt="beam search示意图"  />
</p>
<ul>
<li>在第一个时间步，A和C是最优的两个，因此得到了两个结果<code>[A],[C]</code>，其他三个就被抛弃了；</li>
<li>第二步会基于这两个结果继续进行生成，在A这个分支可以得到5个候选人，<code>[AA],[AB],[AC],[AD],[AE]</code>，C也同理得到5个，此时会对这10个进行统一排名，再保留最优的两个，即图中的<code>[AB]</code>和<code>[CE]</code>；</li>
<li>第三步同理，也会从新的10个候选人里再保留最好的两个，最后得到了<code>[ABD],[CED]</code>两个结果。</li>
</ul>
<p>可以发现，beam search在每一步需要考察的候选人数量是贪心搜索的num_beams倍，因此是一种牺牲时间换性能的方法。</p>
<p>以上就是Beam Search的基本概念，下面我们解析一种高效率实现方式。</p>
<h2 id="beam-search代码解析">Beam Search代码解析<a hidden class="anchor" aria-hidden="true" href="#beam-search代码解析">#</a></h2>
<p>Beam Search的原理虽然简单，但实际实现的时候却有很多细节要考虑。下面要解析这个实现出自于NLP界著名Python包<a href="https://github.com/huggingface/transformers" title="Transformers">Transformers</a>，我为了说明方便做了一些改动。</p>
<p>一个正确且高效的算法需要处理的问题大概有两个：</p>
<ul>
<li>充分利用硬件，可以处理批量数据，且尽量使用并行计算少用循环</li>
<li>处理好长短不同的生成结果</li>
</ul>
<p>下面是基础版的beam search函数定义。其中<code>context</code>是编码器编码获得的向量，<code>batch_size</code>是每批数据中包含的样本量，<code>bos_token_id</code>是句子开头标志的token id，<code>pad_token_id</code>是用于填充的token id，<code>eos_token_id</code>是句子结束标志的token id。这里给参数填上的默认值和我们后面讲解时使用的例子是一致的。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">beam_search_generate</span>(context,
</span></span><span style="display:flex;"><span>                        batch_size<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>,
</span></span><span style="display:flex;"><span>                        max_length<span style="color:#f92672">=</span><span style="color:#ae81ff">20</span>,
</span></span><span style="display:flex;"><span>                        min_length<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>,
</span></span><span style="display:flex;"><span>                        num_beams<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>,
</span></span><span style="display:flex;"><span>                        bos_token_id<span style="color:#f92672">=</span><span style="color:#ae81ff">101</span>,
</span></span><span style="display:flex;"><span>                        pad_token_id<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>,
</span></span><span style="display:flex;"><span>                        eos_token_id<span style="color:#f92672">=</span><span style="color:#ae81ff">102</span>,
</span></span><span style="display:flex;"><span>                        ):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">pass</span>
</span></span></code></pre></div><p>在函数中主要执行以下三个步骤：</p>
<ul>
<li>准备初始输入</li>
<li>在当前生成的序列长度未达到<code>max_length</code>时扩展生成序列</li>
<li>准备最终输出的序列</li>
</ul>
<p>下面我们分别解析。</p>
<h3 id="准备初始输入">准备初始输入<a hidden class="anchor" aria-hidden="true" href="#准备初始输入">#</a></h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># 建立beam容器，每个样本一个</span>
</span></span><span style="display:flex;"><span>generated_hyps <span style="color:#f92672">=</span> [
</span></span><span style="display:flex;"><span>    BeamHypotheses(num_beams, max_length, length_penalty, early_stopping<span style="color:#f92672">=</span>early_stopping)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> _ <span style="color:#f92672">in</span> range(batch_size)
</span></span><span style="display:flex;"><span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 每个beam容器的得分，共batch_size*num_beams个</span>
</span></span><span style="display:flex;"><span>beam_scores <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>zeros((batch_size, num_beams), dtype<span style="color:#f92672">=</span>torch<span style="color:#f92672">.</span>float, device<span style="color:#f92672">=</span>encoder_input_ids<span style="color:#f92672">.</span>device)
</span></span><span style="display:flex;"><span>beam_scores <span style="color:#f92672">=</span> beam_scores<span style="color:#f92672">.</span>view(<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 每个样本是否完成生成，共batch_size个</span>
</span></span><span style="display:flex;"><span>done <span style="color:#f92672">=</span> [<span style="color:#66d9ef">False</span> <span style="color:#66d9ef">for</span> _ <span style="color:#f92672">in</span> range(batch_size)]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 为了并行计算，一次生成batch_size*num_beams个序列</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 第一步自动填入bos_token</span>
</span></span><span style="display:flex;"><span>input_ids <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>full(
</span></span><span style="display:flex;"><span>    (batch_size<span style="color:#f92672">*</span>num_beams, <span style="color:#ae81ff">1</span>),  
</span></span><span style="display:flex;"><span>    bos_token_id,
</span></span><span style="display:flex;"><span>    dtype<span style="color:#f92672">=</span>torch<span style="color:#f92672">.</span>long,
</span></span><span style="display:flex;"><span>    device<span style="color:#f92672">=</span>next(self<span style="color:#f92672">.</span>parameters())<span style="color:#f92672">.</span>device,
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 当前长度设为1</span>
</span></span><span style="display:flex;"><span>cur_len <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>
</span></span></code></pre></div><p>其中<code>BeamHypotheses</code>是一个容器类，每个样本绑定一个。每个容器中会维护<code>num_beams</code>个当前最优的序列。当往容器中添加一个序列而导致序列数大于<code>num_beams</code>的时候，它会自动踢掉分数最低的那个序列。类代码如下。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">BeamHypotheses</span>(object):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self, num_beams, max_length, length_penalty):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        Initialize n-best list of hypotheses.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>max_length <span style="color:#f92672">=</span> max_length <span style="color:#f92672">-</span> <span style="color:#ae81ff">1</span>  <span style="color:#75715e"># ignoring bos_token</span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>num_beams <span style="color:#f92672">=</span> num_beams
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>beams <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>worst_score <span style="color:#f92672">=</span> <span style="color:#ae81ff">1e9</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __len__(self):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        Number of hypotheses in the list.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> len(self<span style="color:#f92672">.</span>beams)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">add</span>(self, hyp, sum_logprobs):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        Add a new hypothesis to the list.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        score <span style="color:#f92672">=</span> sum_logprobs <span style="color:#f92672">/</span> len(hyp) <span style="color:#f92672">**</span> self<span style="color:#f92672">.</span>length_penalty
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> len(self) <span style="color:#f92672">&lt;</span> self<span style="color:#f92672">.</span>num_beams <span style="color:#f92672">or</span> score <span style="color:#f92672">&gt;</span> self<span style="color:#f92672">.</span>worst_score:
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># 可更新的情况：数量未饱和或超过最差得分</span>
</span></span><span style="display:flex;"><span>            self<span style="color:#f92672">.</span>beams<span style="color:#f92672">.</span>append((score, hyp))
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">if</span> len(self) <span style="color:#f92672">&gt;</span> self<span style="color:#f92672">.</span>num_beams:
</span></span><span style="display:flex;"><span>                <span style="color:#75715e"># 数量饱和需要删掉一个最差的</span>
</span></span><span style="display:flex;"><span>                sorted_scores <span style="color:#f92672">=</span> sorted([(s, idx) <span style="color:#66d9ef">for</span> idx, (s, _) <span style="color:#f92672">in</span> enumerate(self<span style="color:#f92672">.</span>beams)])
</span></span><span style="display:flex;"><span>                <span style="color:#66d9ef">del</span> self<span style="color:#f92672">.</span>beams[sorted_scores[<span style="color:#ae81ff">0</span>][<span style="color:#ae81ff">1</span>]]
</span></span><span style="display:flex;"><span>                self<span style="color:#f92672">.</span>worst_score <span style="color:#f92672">=</span> sorted_scores[<span style="color:#ae81ff">1</span>][<span style="color:#ae81ff">0</span>]
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>                self<span style="color:#f92672">.</span>worst_score <span style="color:#f92672">=</span> min(score, self<span style="color:#f92672">.</span>worst_score)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">is_done</span>(self, best_sum_logprobs, cur_len<span style="color:#f92672">=</span><span style="color:#66d9ef">None</span>):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        相关样本是否已经完成生成。
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        best_sum_logprobs是新的候选序列中的最高得分。
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> len(self) <span style="color:#f92672">&lt;</span> self<span style="color:#f92672">.</span>num_beams:
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">return</span> <span style="color:#66d9ef">False</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">if</span> cur_len <span style="color:#f92672">is</span> <span style="color:#66d9ef">None</span>:
</span></span><span style="display:flex;"><span>                cur_len <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>max_length
</span></span><span style="display:flex;"><span>            cur_score <span style="color:#f92672">=</span> best_sum_logprobs <span style="color:#f92672">/</span> cur_len <span style="color:#f92672">**</span> self<span style="color:#f92672">.</span>length_penalty
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># 是否最高分比当前保存的最低分还差</span>
</span></span><span style="display:flex;"><span>            ret <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>worst_score <span style="color:#f92672">&gt;=</span> cur_score
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">return</span> ret
</span></span></code></pre></div><h3 id="序列扩展">序列扩展<a hidden class="anchor" aria-hidden="true" href="#序列扩展">#</a></h3>
<p>序列扩展是beam search的核心过程，我们特地画了一张图来解释这个版本的实现策略。</p>
<p><img loading="lazy" src="/assets/beamsearch/seqextend.png" alt="序列扩展示意图"  />
</p>
<p>下面对照这个图来讲解代码。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">while</span> cur_len <span style="color:#f92672">&lt;</span> max_length:
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 将编码器得到的上下文向量和当前结果输入解码器，即图中1</span>
</span></span><span style="display:flex;"><span>    output <span style="color:#f92672">=</span> decoder<span style="color:#f92672">.</span>decode_next_step(context, input_ids)
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 输出矩阵维度为：(batch*num_beams)*cur_len*vocab_size</span>
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 取出最后一个时间步的各token概率，即当前条件概率</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># (batch*num_beams)*vocab_size</span>
</span></span><span style="display:flex;"><span>    scores <span style="color:#f92672">=</span> next_token_logits <span style="color:#f92672">=</span> output[:, <span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>, :]  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">###########################</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 这里可以做一大堆操作减少重复 #</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">###########################</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 计算序列条件概率的，因为取了log，所以直接相加即可。得到图中2矩阵</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># (batch_size * num_beams, vocab_size)</span>
</span></span><span style="display:flex;"><span>    next_scores <span style="color:#f92672">=</span> scores <span style="color:#f92672">+</span> beam_scores[:, <span style="color:#66d9ef">None</span>]<span style="color:#f92672">.</span>expand_as(scores)  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 为了提速，将结果重排成图中3的形状</span>
</span></span><span style="display:flex;"><span>    next_scores <span style="color:#f92672">=</span> next_scores<span style="color:#f92672">.</span>view(
</span></span><span style="display:flex;"><span>            batch_size, num_beams <span style="color:#f92672">*</span> vocab_size
</span></span><span style="display:flex;"><span>        )  <span style="color:#75715e"># (batch_size, num_beams * vocab_size)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 取出分数最高的token（图中黑点）和其对应得分</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># sorted=True，保证返回序列是有序的</span>
</span></span><span style="display:flex;"><span>    next_scores, next_tokens <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>topk(next_scores, <span style="color:#ae81ff">2</span> <span style="color:#f92672">*</span> num_beams, dim<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>, largest<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, sorted<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 下一个时间步整个batch的beam列表</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 列表中的每一个元素都是三元组</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># (分数, token_id, beam_id)</span>
</span></span><span style="display:flex;"><span>    next_batch_beam <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 对每一个样本进行扩展</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> batch_idx <span style="color:#f92672">in</span> range(batch_size):
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 检查样本是否已经生成结束</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> done[batch_idx]:
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># 对于已经结束的句子，待添加的是pad token</span>
</span></span><span style="display:flex;"><span>            next_batch_beam<span style="color:#f92672">.</span>extend([(<span style="color:#ae81ff">0</span>, pad_token_id, <span style="color:#ae81ff">0</span>)] <span style="color:#f92672">*</span> num_beams)  <span style="color:#75715e"># pad the batch</span>
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">continue</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 当前样本下一个时间步的beam列表</span>
</span></span><span style="display:flex;"><span>        next_sent_beam <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 对于还未结束的样本需要找到分数最高的num_beams个扩展</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 注意，next_scores和next_tokens是对应的</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 而且已经按照next_scores排好顺序</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> beam_token_rank, (beam_token_id, beam_token_score) <span style="color:#f92672">in</span> enumerate(
</span></span><span style="display:flex;"><span>            zip(next_tokens[batch_idx], next_scores[batch_idx])
</span></span><span style="display:flex;"><span>        ):
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># get beam and word IDs</span>
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># 这两行可参考图中3进行理解</span>
</span></span><span style="display:flex;"><span>            beam_id <span style="color:#f92672">=</span> beam_token_id <span style="color:#f92672">//</span> vocab_size 
</span></span><span style="display:flex;"><span>            token_id <span style="color:#f92672">=</span> beam_token_id <span style="color:#f92672">%</span> vocab_size
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>            effective_beam_id <span style="color:#f92672">=</span> batch_idx <span style="color:#f92672">*</span> num_beams <span style="color:#f92672">+</span> beam_id
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># 如果出现了EOS token说明已经生成了完整句子</span>
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">if</span> (eos_token_id <span style="color:#f92672">is</span> <span style="color:#f92672">not</span> <span style="color:#66d9ef">None</span>) <span style="color:#f92672">and</span> (token_id<span style="color:#f92672">.</span>item() <span style="color:#f92672">==</span> eos_token_id):
</span></span><span style="display:flex;"><span>                <span style="color:#75715e"># if beam_token does not belong to top num_beams tokens, it should not be added</span>
</span></span><span style="display:flex;"><span>                is_beam_token_worse_than_top_num_beams <span style="color:#f92672">=</span> beam_token_rank <span style="color:#f92672">&gt;=</span> num_beams
</span></span><span style="display:flex;"><span>                <span style="color:#66d9ef">if</span> is_beam_token_worse_than_top_num_beams:
</span></span><span style="display:flex;"><span>                    <span style="color:#66d9ef">continue</span>
</span></span><span style="display:flex;"><span>                <span style="color:#75715e"># 往容器中添加这个序列</span>
</span></span><span style="display:flex;"><span>                generated_hyps[batch_idx]<span style="color:#f92672">.</span>add(
</span></span><span style="display:flex;"><span>                    input_ids[effective_beam_id]<span style="color:#f92672">.</span>clone(), beam_token_score<span style="color:#f92672">.</span>item(),
</span></span><span style="display:flex;"><span>                )
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>                <span style="color:#75715e"># add next predicted word if it is not eos_token</span>
</span></span><span style="display:flex;"><span>                next_sent_beam<span style="color:#f92672">.</span>append((beam_token_score, token_id, effective_beam_id))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># 扩展num_beams个就够了</span>
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">if</span> len(next_sent_beam) <span style="color:#f92672">==</span> num_beams:
</span></span><span style="display:flex;"><span>                <span style="color:#66d9ef">break</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 检查这个样本是否已经生成完了，有两种情况</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 1. 已经记录过该样本结束</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 2. 新的结果没有使结果改善</span>
</span></span><span style="display:flex;"><span>        done[batch_idx] <span style="color:#f92672">=</span> done[batch_idx] <span style="color:#f92672">or</span> generated_hyps[batch_idx]<span style="color:#f92672">.</span>is_done(
</span></span><span style="display:flex;"><span>            next_scores[batch_idx]<span style="color:#f92672">.</span>max()<span style="color:#f92672">.</span>item(), cur_len<span style="color:#f92672">=</span>cur_len
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 把当前样本的结果添加到batch结果的后面</span>
</span></span><span style="display:flex;"><span>        next_batch_beam<span style="color:#f92672">.</span>extend(next_sent_beam)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 如果全部样本都已经生成结束便可以直接退出了</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> all(done):
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">break</span>
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 把三元组列表再还原成三个独立列表</span>
</span></span><span style="display:flex;"><span>    beam_scores <span style="color:#f92672">=</span> beam_scores<span style="color:#f92672">.</span>new([x[<span style="color:#ae81ff">0</span>] <span style="color:#66d9ef">for</span> x <span style="color:#f92672">in</span> next_batch_beam])
</span></span><span style="display:flex;"><span>    beam_tokens <span style="color:#f92672">=</span> input_ids<span style="color:#f92672">.</span>new([x[<span style="color:#ae81ff">1</span>] <span style="color:#66d9ef">for</span> x <span style="color:#f92672">in</span> next_batch_beam])
</span></span><span style="display:flex;"><span>    beam_idx <span style="color:#f92672">=</span> input_ids<span style="color:#f92672">.</span>new([x[<span style="color:#ae81ff">2</span>] <span style="color:#66d9ef">for</span> x <span style="color:#f92672">in</span> next_batch_beam])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 准备下一时刻的解码器输入</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 取出实际被扩展的beam</span>
</span></span><span style="display:flex;"><span>    input_ids <span style="color:#f92672">=</span> input_ids[beam_idx, :]
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 在这些beam后面接上新生成的token</span>
</span></span><span style="display:flex;"><span>    input_ids <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>cat([input_ids, beam_tokens<span style="color:#f92672">.</span>unsqueeze(<span style="color:#ae81ff">1</span>)], dim<span style="color:#f92672">=-</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 更新当前长度</span>
</span></span><span style="display:flex;"><span>    cur_len <span style="color:#f92672">=</span> cur_len <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># end of length while</span>
</span></span></code></pre></div><p>乍一看是不是有些复杂，我感觉关键的有以下几点：</p>
<ul>
<li>只有出现了EOS token才会将生成的序列装进该样本对应的容器中</li>
<li>当前input_ids保存着当前得分最高的num_beams个序列</li>
</ul>
<h3 id="准备输出">准备输出<a hidden class="anchor" aria-hidden="true" href="#准备输出">#</a></h3>
<p>上面那个while循环跳出意味着已经生成了长度为<code>max_length</code>的文本，比较理想的情况是所有的句子都已经生成出了<code>eos_token_id</code>，即句子生成结束了。但并不是所有情况都这样，对于那些”意犹未尽“的样本，我们需要先手动结束。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># 将未结束的生成结果结束，并置入容器中</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> batch_idx <span style="color:#f92672">in</span> range(batch_size):
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 已经结束的样本不需处理</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> done[batch_idx]:
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">continue</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 把结果加入到generated_hyps容器</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> beam_id <span style="color:#f92672">in</span> range(num_beams):
</span></span><span style="display:flex;"><span>        effective_beam_id <span style="color:#f92672">=</span> batch_idx <span style="color:#f92672">*</span> num_beams <span style="color:#f92672">+</span> beam_id
</span></span><span style="display:flex;"><span>        final_score <span style="color:#f92672">=</span> beam_scores[effective_beam_id]<span style="color:#f92672">.</span>item()
</span></span><span style="display:flex;"><span>        final_tokens <span style="color:#f92672">=</span> input_ids[effective_beam_id]
</span></span><span style="display:flex;"><span>        generated_hyps[batch_idx]<span style="color:#f92672">.</span>add(final_tokens, final_score)
</span></span></code></pre></div><p>经过上面的处理，所有生成好的句子都已经保存在<code>generated_hyps</code>容器中，每个容器内保存着num_beams个序列，最后就是输出期望个数的句子。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># select the best hypotheses，最终输出</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 每个样本返回几个句子</span>
</span></span><span style="display:flex;"><span>output_num_return_sequences_per_batch <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 记录每个返回句子的长度，用于后面pad</span>
</span></span><span style="display:flex;"><span>sent_lengths <span style="color:#f92672">=</span> input_ids<span style="color:#f92672">.</span>new(output_batch_size)
</span></span><span style="display:flex;"><span>best <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 对每个样本取出最好的output_num_return_sequences_per_batch个句子</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> i, hypotheses <span style="color:#f92672">in</span> enumerate(generated_hyps):
</span></span><span style="display:flex;"><span>    sorted_hyps <span style="color:#f92672">=</span> sorted(hypotheses<span style="color:#f92672">.</span>beams, key<span style="color:#f92672">=</span><span style="color:#66d9ef">lambda</span> x: x[<span style="color:#ae81ff">0</span>])
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> j <span style="color:#f92672">in</span> range(output_num_return_sequences_per_batch):
</span></span><span style="display:flex;"><span>        effective_batch_idx <span style="color:#f92672">=</span> output_num_return_sequences_per_batch <span style="color:#f92672">*</span> i <span style="color:#f92672">+</span> j
</span></span><span style="display:flex;"><span>        best_hyp <span style="color:#f92672">=</span> sorted_hyps<span style="color:#f92672">.</span>pop()[<span style="color:#ae81ff">1</span>]
</span></span><span style="display:flex;"><span>        sent_lengths[effective_batch_idx] <span style="color:#f92672">=</span> len(best_hyp)
</span></span><span style="display:flex;"><span>        best<span style="color:#f92672">.</span>append(best_hyp)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 如果长短不一则pad句子，使得最后返回结果的长度一样</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> sent_lengths<span style="color:#f92672">.</span>min()<span style="color:#f92672">.</span>item() <span style="color:#f92672">!=</span> sent_lengths<span style="color:#f92672">.</span>max()<span style="color:#f92672">.</span>item():
</span></span><span style="display:flex;"><span>    sent_max_len <span style="color:#f92672">=</span> min(sent_lengths<span style="color:#f92672">.</span>max()<span style="color:#f92672">.</span>item() <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span>, max_length)
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 先把输出矩阵填满PAD token</span>
</span></span><span style="display:flex;"><span>    decoded <span style="color:#f92672">=</span> input_ids<span style="color:#f92672">.</span>new(output_batch_size, sent_max_len)<span style="color:#f92672">.</span>fill_(pad_token_id)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 填入真正的内容</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> i, hypo <span style="color:#f92672">in</span> enumerate(best):
</span></span><span style="display:flex;"><span>        decoded[i, : sent_lengths[i]] <span style="color:#f92672">=</span> hypo
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 填上eos token</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> sent_lengths[i] <span style="color:#f92672">&lt;</span> max_length:
</span></span><span style="display:flex;"><span>            decoded[i, sent_lengths[i]] <span style="color:#f92672">=</span> eos_token_id
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 所有生成序列都还没结束，直接堆叠即可</span>
</span></span><span style="display:flex;"><span>    decoded <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>stack(best)<span style="color:#f92672">.</span>type(torch<span style="color:#f92672">.</span>long)<span style="color:#f92672">.</span>to(next(self<span style="color:#f92672">.</span>parameters())<span style="color:#f92672">.</span>device)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 返回的结果包含BOS token</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">return</span> decoded
</span></span></code></pre></div><h2 id="总结">总结<a hidden class="anchor" aria-hidden="true" href="#总结">#</a></h2>
<p>好了，上面就是最基础的beam search算法。这样生成出来的结果已经会比贪心搜索好一些，但还是会遇到诸如<strong>词语重复</strong>这样的问题。其实已经有很多针对<strong>重复</strong>问题的研究，我们在代码中也已经留出了位置，下期再说咯。</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://www.yuanhao.site/tags/nlp/">NLP</a></li>
      <li><a href="https://www.yuanhao.site/tags/%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90/">文本生成</a></li>
      <li><a href="https://www.yuanhao.site/tags/beam-search/">beam search</a></li>
    </ul>
<nav class="paginav">
  <a class="prev" href="https://www.yuanhao.site/post/2020-03-23-beamsearch2/">
    <span class="title">« Prev</span>
    <br>
    <span>十分钟读懂beam search-2</span>
  </a>
  <a class="next" href="https://www.yuanhao.site/post/2020-03-07-mips/">
    <span class="title">Next »</span>
    <br>
    <span>最近邻搜索，MIPS，LSH和ALSH</span>
  </a>
</nav>


<ul class="share-buttons">
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share 十分钟读懂beam search-1 on x"
            href="https://x.com/intent/tweet/?text=%e5%8d%81%e5%88%86%e9%92%9f%e8%af%bb%e6%87%82beam%20search-1&amp;url=https%3a%2f%2fwww.yuanhao.site%2fpost%2f2020-03-20-beamsearch1%2f&amp;hashtags=NLP%2c%e6%96%87%e6%9c%ac%e7%94%9f%e6%88%90%2cbeamsearch">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M512 62.554 L 512 449.446 C 512 483.97 483.97 512 449.446 512 L 62.554 512 C 28.03 512 0 483.97 0 449.446 L 0 62.554 C 0 28.03 28.029 0 62.554 0 L 449.446 0 C 483.971 0 512 28.03 512 62.554 Z M 269.951 190.75 L 182.567 75.216 L 56 75.216 L 207.216 272.95 L 63.9 436.783 L 125.266 436.783 L 235.9 310.383 L 332.567 436.783 L 456 436.783 L 298.367 228.367 L 432.367 75.216 L 371.033 75.216 Z M 127.633 110 L 164.101 110 L 383.481 400.065 L 349.5 400.065 Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share 十分钟读懂beam search-1 on linkedin"
            href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fwww.yuanhao.site%2fpost%2f2020-03-20-beamsearch1%2f&amp;title=%e5%8d%81%e5%88%86%e9%92%9f%e8%af%bb%e6%87%82beam%20search-1&amp;summary=%e5%8d%81%e5%88%86%e9%92%9f%e8%af%bb%e6%87%82beam%20search-1&amp;source=https%3a%2f%2fwww.yuanhao.site%2fpost%2f2020-03-20-beamsearch1%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share 十分钟读懂beam search-1 on reddit"
            href="https://reddit.com/submit?url=https%3a%2f%2fwww.yuanhao.site%2fpost%2f2020-03-20-beamsearch1%2f&title=%e5%8d%81%e5%88%86%e9%92%9f%e8%af%bb%e6%87%82beam%20search-1">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share 十分钟读懂beam search-1 on facebook"
            href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fwww.yuanhao.site%2fpost%2f2020-03-20-beamsearch1%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share 十分钟读懂beam search-1 on whatsapp"
            href="https://api.whatsapp.com/send?text=%e5%8d%81%e5%88%86%e9%92%9f%e8%af%bb%e6%87%82beam%20search-1%20-%20https%3a%2f%2fwww.yuanhao.site%2fpost%2f2020-03-20-beamsearch1%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share 十分钟读懂beam search-1 on telegram"
            href="https://telegram.me/share/url?text=%e5%8d%81%e5%88%86%e9%92%9f%e8%af%bb%e6%87%82beam%20search-1&amp;url=https%3a%2f%2fwww.yuanhao.site%2fpost%2f2020-03-20-beamsearch1%2f">
            <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
                <path
                    d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share 十分钟读懂beam search-1 on ycombinator"
            href="https://news.ycombinator.com/submitlink?t=%e5%8d%81%e5%88%86%e9%92%9f%e8%af%bb%e6%87%82beam%20search-1&u=https%3a%2f%2fwww.yuanhao.site%2fpost%2f2020-03-20-beamsearch1%2f">
            <svg version="1.1" xml:space="preserve" width="30px" height="30px" viewBox="0 0 512 512" fill="currentColor"
                xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape">
                <path
                    d="M449.446 0C483.971 0 512 28.03 512 62.554L512 449.446C512 483.97 483.97 512 449.446 512L62.554 512C28.03 512 0 483.97 0 449.446L0 62.554C0 28.03 28.029 0 62.554 0L449.446 0ZM183.8767 87.9921H121.8427L230.6673 292.4508V424.0079H281.3328V292.4508L390.1575 87.9921H328.1233L256 238.2489z" />
            </svg>
        </a>
    </li>
</ul>

  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2024 <a href="https://www.yuanhao.site">多头注意力</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
